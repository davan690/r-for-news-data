<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>3 Sources {sources} | R for Newspaper Data</title>
  <meta name="description" content="This is a book to help new and existing users find and analyse historical newspaper data, using the programming language R-Studio." />
  <meta name="generator" content="bookdown 0.16 and GitBook 2.6.7" />

  <meta property="og:title" content="3 Sources {sources} | R for Newspaper Data" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a book to help new and existing users find and analyse historical newspaper data, using the programming language R-Studio." />
  <meta name="github-repo" content="yannryanBL/r-for-news-data" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3 Sources {sources} | R for Newspaper Data" />
  
  <meta name="twitter:description" content="This is a book to help new and existing users find and analyse historical newspaper data, using the programming language R-Studio." />
  

<meta name="author" content="Yann Ryan" />


<meta name="date" content="2019-12-11" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="introduction-intro.html"/>
<link rel="next" href="methods-1.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />












</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Needed</a></li>
<li class="chapter" data-level="2" data-path="introduction-intro.html"><a href="introduction-intro.html"><i class="fa fa-check"></i><b>2</b> Introduction {intro}</a><ul>
<li class="chapter" data-level="2.1" data-path="introduction-intro.html"><a href="introduction-intro.html#goals"><i class="fa fa-check"></i><b>2.1</b> Goals</a></li>
<li class="chapter" data-level="2.2" data-path="introduction-intro.html"><a href="introduction-intro.html#format-of-the-book---bookdown-and-github"><i class="fa fa-check"></i><b>2.2</b> Format of the book - bookdown and github</a><ul>
<li class="chapter" data-level="2.2.1" data-path="introduction-intro.html"><a href="introduction-intro.html#who-uses-r"><i class="fa fa-check"></i><b>2.2.1</b> Who uses R?</a></li>
<li class="chapter" data-level="2.2.2" data-path="introduction-intro.html"><a href="introduction-intro.html#the-tidyverse"><i class="fa fa-check"></i><b>2.2.2</b> The Tidyverse</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="introduction-intro.html"><a href="introduction-intro.html#sources"><i class="fa fa-check"></i><b>2.3</b> Sources</a><ul>
<li class="chapter" data-level="2.3.1" data-path="introduction-intro.html"><a href="introduction-intro.html#country-by-country"><i class="fa fa-check"></i><b>2.3.1</b> Country by country</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="introduction-intro.html"><a href="introduction-intro.html#methods"><i class="fa fa-check"></i><b>2.4</b> Methods</a><ul>
<li class="chapter" data-level="2.4.1" data-path="introduction-intro.html"><a href="introduction-intro.html#network-analysis-of-seventeenth-century"><i class="fa fa-check"></i><b>2.4.1</b> Network analysis of seventeenth century</a></li>
<li class="chapter" data-level="2.4.2" data-path="introduction-intro.html"><a href="introduction-intro.html#mapping"><i class="fa fa-check"></i><b>2.4.2</b> Mapping</a></li>
<li class="chapter" data-level="2.4.3" data-path="introduction-intro.html"><a href="introduction-intro.html#geocoding"><i class="fa fa-check"></i><b>2.4.3</b> Geocoding</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="introduction-intro.html"><a href="introduction-intro.html#text-mining"><i class="fa fa-check"></i><b>2.5</b> Text mining</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="sources-sources.html"><a href="sources-sources.html"><i class="fa fa-check"></i><b>3</b> Sources {sources}</a><ul>
<li class="chapter" data-level="3.0.1" data-path="sources-sources.html"><a href="sources-sources.html#uk"><i class="fa fa-check"></i><b>3.0.1</b> UK</a></li>
<li class="chapter" data-level="3.0.2" data-path="sources-sources.html"><a href="sources-sources.html#outside-uk"><i class="fa fa-check"></i><b>3.0.2</b> Outside UK:</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="methods-1.html"><a href="methods-1.html"><i class="fa fa-check"></i><b>4</b> Methods</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">R for Newspaper Data</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="sources-sources" class="section level1">
<h1><span class="header-section-number">3</span> Sources {sources}</h1>
<p>Sources</p>
<p>Lancaster Newsbooks Burney Collection EEBO EEBO TCP (pamphlets) BNA HMD newspapers JISC through GALE</p>
<div id="uk" class="section level3">
<h3><span class="header-section-number">3.0.1</span> UK</h3>
<div id="british-newspaper-archive" class="section level4">
<h4><span class="header-section-number">3.0.1.1</span> British newspaper archive</h4>
<p>The British Newspaper Archive is a partnership between FindMyPast and the British Library, digitising newspaper pages from the BL’s collections. The process is ongoing, digitising from microfilm and originals. Pages are segmented and OCRd, and can be full text searched. It is a commercial site and a fee is charged to access content away from BL reading rooms. Material from HMD newspaper digitisation project will most likely be added to the site.</p>
<p>Added 6 million pages last year</p>
<p><a href="https://www.britishnewspaperarchive.co.uk/" class="uri">https://www.britishnewspaperarchive.co.uk/</a></p>
<p>28 million pages</p>
<p>450,000,000 (total physical collection)</p>
<p>Access rights<br />
Free within the BL reading rooms, paid subscription off-site</p>
<p>Features<br />
Download individual pages; OCR; segmentation; search; browse</p>
<p>Example projects Content analysis of 150 years of British Periodicals; Victorian Meme Machine; Protest and the politics of space and place; Frederick Douglas in Britain; Scissors &amp; Paste; Oceanic Exchanges</p>
</div>
</div>
<div id="outside-uk" class="section level3">
<h3><span class="header-section-number">3.0.2</span> Outside UK:</h3>
<div id="chronicling-america" class="section level4">
<h4><span class="header-section-number">3.0.2.1</span> Chronicling America</h4>
<p>Library of Congress U.S</p>
<p>Chronicling America is a Library of Congress initiative providing access to historic newspapers. Grants were given to participants to digitise approximately 100,000 newspaper pages each, which should represent “history, geographic coverage and events of note”. Mostly from microfilm for speed and cost. PDFs are available for download, full text search. CA has an API which allows for the creation of third party applications and sites using the bulk data. Good search functions but difficult to browse by date/region. More information here: <a href="https://oceanicexchanges.org/2018-10-17-data-reports-ca/" class="uri">https://oceanicexchanges.org/2018-10-17-data-reports-ca/</a></p>
<p>Between 1 - 2 million over the past 5 years, 3.3 million pages expected this year.</p>
<p><a href="https://chroniclingamerica.loc.gov/" class="uri">https://chroniclingamerica.loc.gov/</a></p>
<p><a href="https://chroniclingamerica.loc.gov/about/api/" class="uri">https://chroniclingamerica.loc.gov/about/api/</a></p>
<p>14 million pages</p>
<p>(probably impossible to find total as it is a collection of individual State projects)</p>
<p>JPEG2000 and PDF for download</p>
<p>Free - no key needed for API</p>
<p>OCR; segmentation; full text download; search; API</p>
<p>Data Visualization: Journalism’s Journey West; An Epidemiology of Information: Data Mining the 1918 Influenza Epidemic; Bookworm; American Lynching; America’s Public Bible; Historical Agricultural News; Chronicling Hoosier; US News Map</p>
</div>
<div id="delpher" class="section level4">
<h4><span class="header-section-number">3.0.2.2</span> Delpher</h4>
<p>Koninkklijke Bibliotheek Netherlands</p>
<p>Delpher is the Netherland’s national media archive database. It contains 11 million pages of newpapers. It has certain datasets available for bulk download. The front page interface is clean and allows for very quick browsing by date. There is also an associated site labs.kb.nl which hosts datasets and projects. The bulk download has both XML and plain text files, but not images. The site contains 1.5 million newspapers or 11 million pages, representing 15% of all newspapers published. Some external news sources are searchable through Delpher, with the link going through to the external site.</p>
<p>130 titles to be digitised between 2018 - 2021. About 50,000 newspapers (issues) added in 2018.</p>
<p><a href="https://www.delpher.nl/nl/kranten" class="uri">https://www.delpher.nl/nl/kranten</a></p>
<p>Full dataset here: <a href="https://www.delpher.nl/nl/platform/pages/helpitems?nid=513&amp;scrollitem=true" class="uri">https://www.delpher.nl/nl/platform/pages/helpitems?nid=513&amp;scrollitem=true</a>; derived datasets here: <a href="http://lab.kb.nl/datasets?f%5B0%5D=field_product_type%3A1">http://lab.kb.nl/datasets?f%5B0%5D=field_product_type%3A1</a></p>
<p>11 million pages (15% of total) 1.4 million newspapers from national library plus 2.9 million external newspapers.</p>
<p>73,333,333 pages</p>
<p>Funding from Metamorfoze - Netherlands national programme for the preservation of paper heritage. <a href="https://www.metamorfoze.nl/english" class="uri">https://www.metamorfoze.nl/english</a></p>
<p>No images in bulk download. Individual pages can be downloaded as text, JPEG, PDF.</p>
<p>Free access, bulk download until 1876</p>
<p>OCR; segmentation; browse by date; search; bulk download of everything up to 1876; cut clippings and download text or image</p>
<p>Siamese; Frame Generator; Dictionary Viewer; Narralyzer; Genre classifier</p>
</div>
<div id="eluxemburgensia" class="section level4">
<h4><span class="header-section-number">3.0.2.3</span> Eluxemburgensia</h4>
<p>Bibliothéque Nationale de Luxembourg Luxembourg</p>
<p>Luxemburg’s open data sets, currently the only one released is a historical newspaper dataset. Contains a series of ‘packages’, made to look like different versions of a web product or software, with very clear uses for each. XML/ALTO files. Link to a tool which extracts data from the XML, available on GitHub. Segmented and OCRd.</p>
<p>15 - 20k pages per month at peak - carried out by external provider</p>
<p><a href="http://www.eluxemburgensia.lu/R/RN=422843522&amp;local_base=SERIALS" class="uri">http://www.eluxemburgensia.lu/R/RN=422843522&amp;local_base=SERIALS</a>.</p>
<p><a href="http://data.bnl.lu/data/historical-newspapers/" class="uri">http://data.bnl.lu/data/historical-newspapers/</a></p>
<p>650,000 pages, 12% of total</p>
<p>5.4 million</p>
<p>Government funded - through National Library/Ministry of Culture</p>
<p>XML/ALTO and PDF, full text and TIFF images</p>
<p>Free access to bulk downloads, free access to PDF downloads.</p>
<p>OCR; search; segmentation; full text; XML download; bulk download</p>
<p>Brodigues blog uses</p>
</div>
<div id="europeana" class="section level4">
<h4><span class="header-section-number">3.0.2.4</span> Europeana</h4>
<p>Europeana Consortium (funded by the European Union) Europe</p>
<p>Newspapers; images; art; manuscripts; maps; music; others</p>
<p>Europeana is an aggregator for many of Europe’s national newspaper collections, containing 4,129,989 newspapers (issues, presumably, rather than pages). Some are image or full text and other records are metadata only. 876,724 have had OCR processing. Newpapers can be browsed by date, country and title. Can be filtered by rights, which is useful. Images can be downloaded but users are directed back to the original source for more features. The plan is to tag up to 10 million pages with metadata and named entities.</p>
<p>Difficult to tell - about 1,000 additional records tagged ‘newspaper’ were added in 2018.</p>
<p>Currently available through <a href="http://www.theeuropeanlibrary.org/tel4/newspapers" class="uri">http://www.theeuropeanlibrary.org/tel4/newspapers</a> also <a href="https://www.europeana.eu/portal/en/collections/newspapers" class="uri">https://www.europeana.eu/portal/en/collections/newspapers</a> as part of the wider Europeana site.</p>
<p>4129989 newspapers</p>
<p>Funding: European Union</p>
<p>Multiple sources with different restrictions</p>
<p>OCR; search; segmentation; bulk data download; metadata</p>
</div>
<div id="finnish-newspaper-database" class="section level4">
<h4><span class="header-section-number">3.0.2.5</span> Finnish Newspaper Database</h4>
<p>National Library of Finland Finland</p>
<p>Newspapers; journals; maps; ephemera</p>
<p>Finland’s national newspaper digitisation, run by the National Library of Finland. 7 million pages, 4 million of which are free to use and out of copyright. Some extensive tools for users: can download full text, PDF or XML of all pages. Have been OCRd and everything is also available on Europeana. Can be browsed by year and title. There’s also bulk data download available, multiple packages.</p>
<p>Digitising at 1 million pages per year according to <a href="https://oceanicexchanges.org/2018-02-20-data-reports-finland/" class="uri">https://oceanicexchanges.org/2018-02-20-data-reports-finland/</a></p>
<p><a href="https://digi.kansalliskirjasto.fi/etusivu" class="uri">https://digi.kansalliskirjasto.fi/etusivu</a></p>
<p><a href="https://digi.kansalliskirjasto.fi/opendata/submit" class="uri">https://digi.kansalliskirjasto.fi/opendata/submit</a></p>
<p>6.4 million newspaper pages: all material up to 1929 plus more.</p>
<p>6.4 million pages PDF download</p>
<p>Free &amp; open until 1929, restrictions thereafter (approx 4 million pages free access). Bulk downloads are available, N-Gram list and other data packages.</p>
<p>OCR; search; segmentation; full text; XML download for individual pages; bulk data download</p>
<p>“Finnish text reuse (<a href="http://comhis.fi/clusters" class="uri">http://comhis.fi/clusters</a>); Local Letters to Newspapers; Geography of the nineteenth-century “lingonberry rush””</p>
</div>
<div id="gallica" class="section level4">
<h4><span class="header-section-number">3.0.2.6</span> Gallica</h4>
<p>Bibliothéque Nationale de France France</p>
<p>Newspapers; books; manuscripts; images; music sheets; sounds; objects</p>
<p>France’s national newspaper digitisation site, part of their larger digital library of BnF. Intended to have 3.5 million pages, over 30 titles, free of charge. Contains useful search functions, containing snippets of the newspaper image where the term is found. Full text and PDF downloads are available. There’s also some interprative essays on the site, and the newspapers can be browsed by theme. Searches for certain themes or topics result in a ‘Gallica advises’ section above the search results with (presumably curated) information. Can be browsed by region, both region published and region covered.</p>
<p><a href="https://gallica.bnf.fr/html/und/presse-et-revues/les-principaux-quotidiens" class="uri">https://gallica.bnf.fr/html/und/presse-et-revues/les-principaux-quotidiens</a></p>
<p>2.3 million images/pages PDF, JPEG Free and open for early material OCR; search; browse by date; browse by region;</p>
</div>
<div id="trove" class="section level4">
<h4><span class="header-section-number">3.0.2.7</span> Trove</h4>
<p>National Library of Australia Australia</p>
<p>Newspapers; Govt. Gazettes; Journals &amp; datasets; books; pictures &amp; photos; sound, music &amp; video; diaries &amp; letters; websites; people</p>
<p>Trove is an online database of resources relating to Australia, including newspapers and other material. It is a centralised repository for material from a large number of suppliers, including 221,289,583 newspaper articles. Trove has a very effective and useful API and is used by lots of external researchers as well as for commerical use. The metadata about resources is processed for searching via the website and API, but Trove actually hosts the newspaper content themselves. They also have user tools such as making corrections, tagging etc with a substantial volunteer community making changes. More information here: <a href="https://oceanicexchanges.org/2018-05-29-data-reports-trove/" class="uri">https://oceanicexchanges.org/2018-05-29-data-reports-trove/</a></p>
<p>400,000 pages in the past financial year.</p>
<p><a href="https://trove.nla.gov.au/newspaper/" class="uri">https://trove.nla.gov.au/newspaper/</a></p>
<p><a href="http://help.nla.gov.au/trove/building-with-trove/api" class="uri">http://help.nla.gov.au/trove/building-with-trove/api</a></p>
<p>24 million pages</p>
<p>3,800 titles pre-1955. 1,500 of these have been digitised.</p>
<p>Funded by National Library but also State and local libraries sometimes pay to have their material digitised/uploaded PDF download</p>
<p>Free, open API. Material is mostly pre-1955 and therefore can be digitised without copyright agreement. Some post-1955 material with agreement from the publishers.</p>
<p>OCR; segmentation; search;browse by date; API; metadata</p>
<p>Drifter; Culture collage; Eyes on the Past; The Front Page; Trove Zone Explorer</p>
</div>
<div id="papers-past" class="section level4">
<h4><span class="header-section-number">3.0.2.8</span> Papers Past</h4>
<p>National Library of New Zealand New Zealand</p>
<p>Newspapers; magazines &amp; journals; Letters &amp; Diaries; Parliamentary papers</p>
<p>Papers Past is New Zealand’s digitised document resource. It has four sections: Newspapers, Magazines &amp; Journals, Letters &amp; Diaries and Parliamentary Papers. The Newspaper collection is a selection of digitised NZ and Pacific newspapers, including early te reo Maori ones. Content is searchable, and it is possible to browse by date, title or region. Each title has a mini-history on the site. No indication of how much material has been digitised as a percentage of total. Particularly high-quality scans and accurate OCR/segmentation.</p>
<p>350-400k pages per year</p>
<p><a href="https://paperspast.natlib.govt.nz/newspapers" class="uri">https://paperspast.natlib.govt.nz/newspapers</a></p>
<p>Supplied on case-by-case basis</p>
<p>40% available through digitalnz.org API</p>
<p>5.4 million pages</p>
<p>Free open access. Images and text can be printed. Assumption that anything over 100 years is out of copyright.</p>
<p>OCR; segmentation; search;browse by date</p>
</div>
<div id="hemeroteca-nacional-digital-de-mexico" class="section level4">
<h4><span class="header-section-number">3.0.2.9</span> Hemeroteca Nacional Digital de Mexico</h4>
<p>(1735–1969) This is the national newspaper collection of Mexico. Titles from 1722 - 2010, with restrictions on newer content. Has full-text search but doesn’t seem to have access to full text download. Restrictions on PDF downloads. Some basic visualisations and information on the most consulted titles.</p>
<p><a href="http://www.hndm.unam.mx/index.php/es/" class="uri">http://www.hndm.unam.mx/index.php/es/</a></p>
</div>
<div id="belgica-press" class="section level4">
<h4><span class="header-section-number">3.0.2.10</span> Belgica Press</h4>
<p>This is Belgium’s national newspaper digitisation project. 4 million pages have been digitised, from 1831 to 1950, for a select number of titles (L’Echo De La Presse, Gazet Van Brussel, Het Handelsblad, L’Indépendance Belge (printed in Britain), Le Messager De Gand, De Nieuwe Gids, De Nieuwe Standaard and Het Nieuws Van Den Dag). Up to 1919 is freely available online. Seems to have full text search but not download, and no easy way to download full images.</p>
<p><a href="https://www.belgicapress.be/" class="uri">https://www.belgicapress.be/</a></p>
<p>4.2 million pages, 1.2 million available externaly (rest within library)</p>
<p>Restrictions on PDF download and full text versions, material after 1919.</p>
<p>OCR; search; browse by date</p>
</div>
<div id="welsh-newspaper-archive" class="section level4">
<h4><span class="header-section-number">3.0.2.11</span> Welsh Newspaper Archive</h4>
<p>To fill in - have a large collection</p>
</div>
<div id="national-library-of-scotland" class="section level4">
<h4><span class="header-section-number">3.0.2.12</span> National Library of Scotland</h4>
</div>
<div id="italian-newspapers" class="section level4">
<h4><span class="header-section-number">3.0.2.13</span> Italian newspapers</h4>
<p>Doesn’t seem to be any centralised repository, but various archives are available through the websites of individual newspapers.</p>
</div>
<div id="hemeroteca-digital-spain" class="section level4">
<h4><span class="header-section-number">3.0.2.14</span> Hemeroteca Digital (Spain)</h4>
</div>
<div id="anno---austrian-newspapers-online" class="section level4">
<h4><span class="header-section-number">3.0.2.15</span> ANNO - Austrian Newspapers Online</h4>
<p>Anno is Austria’s national digital newspaper collection. It contains 500 titles, over 10 million pages, from the 16th century to the 1940s. They are mostly OCRd and can be full-text searched. The site can be browsed by title or date, through a calendar.</p>
</div>
<div id="bc-historical-newspapers" class="section level4">
<h4><span class="header-section-number">3.0.2.16</span> BC Historical Newspapers</h4>
<p>The BC Historical Newspapers project features digitized versions of historical papers from around the province. The titles, which range from the Abbotsford Post to the Ymir Mirror, date from 1859 to 1995. Has some pretty advanced browse and search features, and can download PDFs, full text and metadata files. <a href="https://open.library.ubc.ca/collections/bcnewspapers" class="uri">https://open.library.ubc.ca/collections/bcnewspapers</a></p>
<p>OCR; full text download; metadata download; browse by date, title</p>
</div>
<div id="media-stream" class="section level4">
<h4><span class="header-section-number">3.0.2.17</span> Media Stream</h4>
<p>Media Stream is Denmark’s web access for the Royal Library’s newspaper, radio and television commercials. 35 million pages of newspapers have been digitised, access to anything after January 1919 is available only in the library itself. The archive has full-text search, but seemingly no way to access the full text of individual articles. Pre 1919 material can be downloaded as PDFs. There’s also a link to a tutorial on how to search.</p>
<p><a href="http://www2.statsbiblioteket.dk/mediestream/avis" class="uri">http://www2.statsbiblioteket.dk/mediestream/avis</a></p>
<p>35000000 pages PDF, free to 1919 OCR; browse by title</p>
</div>
<div id="stare-hrvatske-novine" class="section level4">
<h4><span class="header-section-number">3.0.2.18</span> Stare hrvatske novine</h4>
<p>Croatia’s national digitised newspapers. Select papers starting from 1789. Limited functionality.</p>
</div>
<div id="zefys" class="section level4">
<h4><span class="header-section-number">3.0.2.19</span> ZEFYS</h4>
<p>Access to holdings in the Staatsbibliothek Berlin and other German newspapers and German newspapers abroad. 276,015 copies of 193 newspapers. Mixed functionality, some are OCRd, others just images. Has a ‘year cloud’ for browsing by year, which also illustrates quickly which years have most quantity of news. Seems to run just from 1890 to 1939.</p>
<p><a href="http://zefys.staatsbibliothek-berlin.de/index.php?id=start" class="uri">http://zefys.staatsbibliothek-berlin.de/index.php?id=start</a></p>
</div>
<div id="timarit.is" class="section level4">
<h4><span class="header-section-number">3.0.2.20</span> Timarit.is</h4>
<p>Newspaper archive for Iceland, Greenland and Faroe Islands. Currently contains 1179 titles, 64683 articles, 5619584 pages (presumably the articles are low because it’s only counting ones that have been segmented successfully). Full text search is available, as is full text and PDF downloads. Can be browsed by titles. Some early titles possibly manuscript.</p>
<p><a href="http://timarit.is/listing_init.jsp?lang=en" class="uri">http://timarit.is/listing_init.jsp?lang=en</a></p>
<p>5619584 pages PDF FREE OCR (limited); full text search; browse by title</p>
</div>
<div id="google-news-archive" class="section level4">
<h4><span class="header-section-number">3.0.2.21</span> Google news archive</h4>
<p>Google news archive originally started as a standalone product but now is incorporated into Google News. Mixture of titles available for searching, but has not been updated since 2011. Significantly has a full archive of the NYT. OCRd, but the text is not browsable or downloadable. Can browse by title or search. Perhaps more functionality on various Google news apps</p>
<p><a href="https://news.google.com/newspapers" class="uri">https://news.google.com/newspapers</a></p>
</div>
<div id="baltic-digital-library" class="section level4">
<h4><span class="header-section-number">3.0.2.22</span> Baltic Digital Library</h4>
<p>Collection of digital objects, including newspapers. Some interesting features including structure (essentially allowing for browsing through titles/issues.</p>
</div>
<div id="newspapersg" class="section level4">
<h4><span class="header-section-number">3.0.2.23</span> NewspaperSG</h4>
<p>Singapore’s national newspaper collection. Newspapers from 1831 onwards, plus a catelogue of the National Library’s microfilm holdings. Interesting ‘search terms visualiser’, essentially an N-Gram timeline, with up to five words at a time. Gives actual numbers rather than relative frequency, which isn’t very helpful if the material is not evenly spread out over the time. Also ‘this week in history’ and ‘most viewed articles’ sections. Search brings up OCR text first, rather than images. Cannot download full files</p>
</div>
<div id="svenska-dagstidningar" class="section level4">
<h4><span class="header-section-number">3.0.2.24</span> Svenska dagstidningar</h4>
<p>Partial Swedish Newspaper archive, containing over 500 titles, from 1645 to the present day. Material up until 1903 is freely available, anything after that only in the reading rooms of various Swedish libraries.</p>
<p><a href="https://tidningar.kb.se/" class="uri">https://tidningar.kb.se/</a></p>
<p>500 titles</p>
</div>
<div id="handwritten-newspapers-project" class="section level4">
<h4><span class="header-section-number">3.0.2.25</span> Handwritten Newspapers Project</h4>
<p>Archive of handwritten news from around the world. First issue is from 1700. Browsable by date. Some images but mostly links or catelogue records</p>
<p><a href="https://handwrittennews.com/" class="uri">https://handwrittennews.com/</a></p>
</div>
<div id="the-medici-archive-project" class="section level4">
<h4><span class="header-section-number">3.0.2.26</span> The Medici Archive Project</h4>
<p>The Medici archive project consists of two parts: Building Interaction Archives (BIA) allows for the querying of manuscript documents, including handwritten news (avvisi). Some have full text transcriptions or English synopses. Documents can be compared via split screen, and there is some ability to browse or search named entities. The Medici Interactive Archive (MIA) is the second part, which intends to make the whole Medici archive available to researchers, including the ability to edit transcriptions, for example.<br />
<a href="http://www.medici.org/" class="uri">http://www.medici.org/</a></p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="introduction-intro.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="methods-1.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
