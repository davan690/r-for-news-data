<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>9 Term Frequencies | Demystifying Newspaper Data with R (and a tiny bit of Python)</title>
  <meta name="description" content="This is a handbook to help new and existing users find, process and analyse historical newspaper data, using the programming language R, and its IDE R-Studio" />
  <meta name="generator" content="bookdown 0.17 and GitBook 2.6.7" />

  <meta property="og:title" content="9 Term Frequencies | Demystifying Newspaper Data with R (and a tiny bit of Python)" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="This is a handbook to help new and existing users find, process and analyse historical newspaper data, using the programming language R, and its IDE R-Studio" />
  <meta name="github-repo" content="yannryanBL/r-for-news-data" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="9 Term Frequencies | Demystifying Newspaper Data with R (and a tiny bit of Python)" />
  
  <meta name="twitter:description" content="This is a handbook to help new and existing users find, process and analyse historical newspaper data, using the programming language R, and its IDE R-Studio" />
  

<meta name="author" content="Yann Ryan" />


<meta name="date" content="2020-02-04" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="extract-text.html"/>
<link rel="next" href="tf-idf.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/htmlwidgets-1.5.1/htmlwidgets.js"></script>
<link href="libs/leaflet-1.3.1/leaflet.css" rel="stylesheet" />
<script src="libs/leaflet-1.3.1/leaflet.js"></script>
<link href="libs/leafletfix-1.0.0/leafletfix.css" rel="stylesheet" />
<script src="libs/Proj4Leaflet-1.0.1/proj4-compressed.js"></script>
<script src="libs/Proj4Leaflet-1.0.1/proj4leaflet.js"></script>
<link href="libs/rstudio_leaflet-1.3.1/rstudio_leaflet.css" rel="stylesheet" />
<script src="libs/leaflet-binding-2.0.3/leaflet.js"></script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Preface &amp; Acknowledgements</a></li>
<li class="chapter" data-level="2" data-path="introduction.html"><a href="introduction.html"><i class="fa fa-check"></i><b>2</b> Introduction</a><ul>
<li class="chapter" data-level="2.1" data-path="introduction.html"><a href="introduction.html#unlocking-the-past-with-newspaper-data"><i class="fa fa-check"></i><b>2.1</b> Unlocking the past with newspaper data</a></li>
<li class="chapter" data-level="2.2" data-path="introduction.html"><a href="introduction.html#why-is-it-useful"><i class="fa fa-check"></i><b>2.2</b> Why is it useful?</a></li>
<li class="chapter" data-level="2.3" data-path="introduction.html"><a href="introduction.html#goals"><i class="fa fa-check"></i><b>2.3</b> Goals</a></li>
<li class="chapter" data-level="2.4" data-path="introduction.html"><a href="introduction.html#why-r"><i class="fa fa-check"></i><b>2.4</b> Why R?</a></li>
<li class="chapter" data-level="2.5" data-path="introduction.html"><a href="introduction.html#who-is-the-book-for"><i class="fa fa-check"></i><b>2.5</b> Who is the book for?</a></li>
<li class="chapter" data-level="2.6" data-path="introduction.html"><a href="introduction.html#format-of-the-book"><i class="fa fa-check"></i><b>2.6</b> Format of the book</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="uk-newspaper-data.html"><a href="uk-newspaper-data.html"><i class="fa fa-check"></i><b>3</b> UK Newspaper Data</a><ul>
<li class="chapter" data-level="3.1" data-path="uk-newspaper-data.html"><a href="uk-newspaper-data.html#intro-to-british-library-newspapers"><i class="fa fa-check"></i><b>3.1</b> Intro to British Library Newspapers</a></li>
<li class="chapter" data-level="3.2" data-path="uk-newspaper-data.html"><a href="uk-newspaper-data.html#burney-collection"><i class="fa fa-check"></i><b>3.2</b> Burney Collection</a></li>
<li class="chapter" data-level="3.3" data-path="uk-newspaper-data.html"><a href="uk-newspaper-data.html#jisc-newspaper-digitisation-projects"><i class="fa fa-check"></i><b>3.3</b> JISC Newspaper digitisation projects</a></li>
<li class="chapter" data-level="3.4" data-path="uk-newspaper-data.html"><a href="uk-newspaper-data.html#british-newspaper-archive"><i class="fa fa-check"></i><b>3.4</b> BRITISH NEWSPAPER ARCHIVE</a></li>
<li class="chapter" data-level="3.5" data-path="uk-newspaper-data.html"><a href="uk-newspaper-data.html#hmd-data--on-repository"><i class="fa fa-check"></i><b>3.5</b> HMD data- on repository</a></li>
<li class="chapter" data-level="3.6" data-path="uk-newspaper-data.html"><a href="uk-newspaper-data.html#what-access-do-you-need"><i class="fa fa-check"></i><b>3.6</b> What access do you need?</a><ul>
<li class="chapter" data-level="3.6.1" data-path="uk-newspaper-data.html"><a href="uk-newspaper-data.html#want-to-find-individual-articles."><i class="fa fa-check"></i><b>3.6.1</b> Want to find individual articles.</a></li>
<li class="chapter" data-level="3.6.2" data-path="uk-newspaper-data.html"><a href="uk-newspaper-data.html#want-to-do-text-mining-on-a-large-corpus"><i class="fa fa-check"></i><b>3.6.2</b> Want to do text mining on a large corpus</a></li>
<li class="chapter" data-level="3.6.3" data-path="uk-newspaper-data.html"><a href="uk-newspaper-data.html#want-to-do-text-mining-on-the-entire-digitised-collection"><i class="fa fa-check"></i><b>3.6.3</b> Want to do text mining on the entire digitised collection</a></li>
<li class="chapter" data-level="3.6.4" data-path="uk-newspaper-data.html"><a href="uk-newspaper-data.html#want-to-do-something-involving-the-images-such-as-computer-vision-techniques"><i class="fa fa-check"></i><b>3.6.4</b> Want to do something involving the images, such as computer vision techniques,</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="ocr-and-its-problems.html"><a href="ocr-and-its-problems.html"><i class="fa fa-check"></i><b>4</b> OCR and its problems</a><ul>
<li class="chapter" data-level="4.1" data-path="ocr-and-its-problems.html"><a href="ocr-and-its-problems.html#what-is-ocr"><i class="fa fa-check"></i><b>4.1</b> What is OCR?</a></li>
<li class="chapter" data-level="4.2" data-path="ocr-and-its-problems.html"><a href="ocr-and-its-problems.html#what-is-it-like-in-bl-newspapers"><i class="fa fa-check"></i><b>4.2</b> What is it like in BL newspapers?</a></li>
<li class="chapter" data-level="4.3" data-path="ocr-and-its-problems.html"><a href="ocr-and-its-problems.html#introduction-1"><i class="fa fa-check"></i><b>4.3</b> Introduction</a></li>
<li class="chapter" data-level="4.4" data-path="ocr-and-its-problems.html"><a href="ocr-and-its-problems.html#extract-predicted-word-scores-from-the-alto-pages"><i class="fa fa-check"></i><b>4.4</b> Extract predicted word scores from the ALTO pages</a></li>
<li class="chapter" data-level="4.5" data-path="ocr-and-its-problems.html"><a href="ocr-and-its-problems.html#visualisations"><i class="fa fa-check"></i><b>4.5</b> Visualisations:</a><ul>
<li class="chapter" data-level="4.5.1" data-path="ocr-and-its-problems.html"><a href="ocr-and-its-problems.html#whats-in-the-data"><i class="fa fa-check"></i><b>4.5.1</b> What’s in the data?</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="ocr-and-its-problems.html"><a href="ocr-and-its-problems.html#highest-and-lowest-results"><i class="fa fa-check"></i><b>4.6</b> Highest and lowest results:</a></li>
<li class="chapter" data-level="4.7" data-path="ocr-and-its-problems.html"><a href="ocr-and-its-problems.html#page-by-page-ocr-visualisation"><i class="fa fa-check"></i><b>4.7</b> Page-by-page OCR visualisation</a></li>
<li class="chapter" data-level="4.8" data-path="ocr-and-its-problems.html"><a href="ocr-and-its-problems.html#microfilm-vs-print"><i class="fa fa-check"></i><b>4.8</b> Microfilm vs print:</a></li>
<li class="chapter" data-level="4.9" data-path="ocr-and-its-problems.html"><a href="ocr-and-its-problems.html#conclusions"><i class="fa fa-check"></i><b>4.9</b> Conclusions</a></li>
<li class="chapter" data-level="4.10" data-path="ocr-and-its-problems.html"><a href="ocr-and-its-problems.html#impact-on-analysis"><i class="fa fa-check"></i><b>4.10</b> Impact on analysis</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="quick-introduction-to-r-and-the-tidyverse.html"><a href="quick-introduction-to-r-and-the-tidyverse.html"><i class="fa fa-check"></i><b>5</b> Quick introduction to R and the tidyverse</a><ul>
<li class="chapter" data-level="5.1" data-path="quick-introduction-to-r-and-the-tidyverse.html"><a href="quick-introduction-to-r-and-the-tidyverse.html#what-and-why"><i class="fa fa-check"></i><b>5.1</b> What and why?</a></li>
<li class="chapter" data-level="5.2" data-path="quick-introduction-to-r-and-the-tidyverse.html"><a href="quick-introduction-to-r-and-the-tidyverse.html#using-r"><i class="fa fa-check"></i><b>5.2</b> Using R</a><ul>
<li class="chapter" data-level="5.2.1" data-path="quick-introduction-to-r-and-the-tidyverse.html"><a href="quick-introduction-to-r-and-the-tidyverse.html#base-r-commands"><i class="fa fa-check"></i><b>5.2.1</b> Base R commands</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="quick-introduction-to-r-and-the-tidyverse.html"><a href="quick-introduction-to-r-and-the-tidyverse.html#tidyverse"><i class="fa fa-check"></i><b>5.3</b> Tidyverse</a><ul>
<li class="chapter" data-level="5.3.1" data-path="quick-introduction-to-r-and-the-tidyverse.html"><a href="quick-introduction-to-r-and-the-tidyverse.html#select-pull"><i class="fa fa-check"></i><b>5.3.1</b> select(), pull()</a></li>
<li class="chapter" data-level="5.3.2" data-path="quick-introduction-to-r-and-the-tidyverse.html"><a href="quick-introduction-to-r-and-the-tidyverse.html#group_by-tally-summarise"><i class="fa fa-check"></i><b>5.3.2</b> group_by(), tally(), summarise()</a></li>
<li class="chapter" data-level="5.3.3" data-path="quick-introduction-to-r-and-the-tidyverse.html"><a href="quick-introduction-to-r-and-the-tidyverse.html#filter"><i class="fa fa-check"></i><b>5.3.3</b> filter()</a></li>
<li class="chapter" data-level="5.3.4" data-path="quick-introduction-to-r-and-the-tidyverse.html"><a href="quick-introduction-to-r-and-the-tidyverse.html#sort-arrange-top_n"><i class="fa fa-check"></i><b>5.3.4</b> sort(), arrange(), top_n()</a></li>
<li class="chapter" data-level="5.3.5" data-path="quick-introduction-to-r-and-the-tidyverse.html"><a href="quick-introduction-to-r-and-the-tidyverse.html#left_join-inner_join-anti_join"><i class="fa fa-check"></i><b>5.3.5</b> left_join(), inner_join(), anti_join()</a></li>
<li class="chapter" data-level="5.3.6" data-path="quick-introduction-to-r-and-the-tidyverse.html"><a href="quick-introduction-to-r-and-the-tidyverse.html#piping"><i class="fa fa-check"></i><b>5.3.6</b> Piping</a></li>
<li class="chapter" data-level="5.3.7" data-path="quick-introduction-to-r-and-the-tidyverse.html"><a href="quick-introduction-to-r-and-the-tidyverse.html#plotting-using-ggplot"><i class="fa fa-check"></i><b>5.3.7</b> Plotting using ggplot()</a></li>
<li class="chapter" data-level="5.3.8" data-path="quick-introduction-to-r-and-the-tidyverse.html"><a href="quick-introduction-to-r-and-the-tidyverse.html#doing-this-with-newspaper-data"><i class="fa fa-check"></i><b>5.3.8</b> Doing this with newspaper data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="geocode-and-map-newspaper-titles.html"><a href="geocode-and-map-newspaper-titles.html"><i class="fa fa-check"></i><b>6</b> Geocode and map newspaper titles</a><ul>
<li class="chapter" data-level="6.1" data-path="geocode-and-map-newspaper-titles.html"><a href="geocode-and-map-newspaper-titles.html#a-map-of-british-newspapers-by-city"><i class="fa fa-check"></i><b>6.1</b> A map of British Newspapers by City</a></li>
<li class="chapter" data-level="6.2" data-path="geocode-and-map-newspaper-titles.html"><a href="geocode-and-map-newspaper-titles.html#drawing-a-background-map."><i class="fa fa-check"></i><b>6.2</b> Drawing a background map. `</a><ul>
<li class="chapter" data-level="6.2.1" data-path="geocode-and-map-newspaper-titles.html"><a href="geocode-and-map-newspaper-titles.html#mapping-with-ggplot2-and-mapdata"><i class="fa fa-check"></i><b>6.2.1</b> Mapping with ggplot2 and mapdata</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="geocode-and-map-newspaper-titles.html"><a href="geocode-and-map-newspaper-titles.html#add-some-points"><i class="fa fa-check"></i><b>6.3</b> Add some points</a><ul>
<li class="chapter" data-level="6.3.1" data-path="geocode-and-map-newspaper-titles.html"><a href="geocode-and-map-newspaper-titles.html#get-a-count-of-the-total-titles-for-each-city"><i class="fa fa-check"></i><b>6.3.1</b> Get a count of the total titles for each city</a></li>
<li class="chapter" data-level="6.3.2" data-path="geocode-and-map-newspaper-titles.html"><a href="geocode-and-map-newspaper-titles.html#get-a-list-of-points."><i class="fa fa-check"></i><b>6.3.2</b> Get a list of points.</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="geocode-and-map-newspaper-titles.html"><a href="geocode-and-map-newspaper-titles.html#choropleth-map"><i class="fa fa-check"></i><b>6.4</b> Choropleth map</a></li>
<li class="chapter" data-level="6.5" data-path="geocode-and-map-newspaper-titles.html"><a href="geocode-and-map-newspaper-titles.html#make-the-points-object."><i class="fa fa-check"></i><b>6.5</b> Make the points object.</a></li>
</ul></li>
<li class="part"><span><b>I Part III: Examples</b></span></li>
<li class="chapter" data-level="7" data-path="text-mining.html"><a href="text-mining.html"><i class="fa fa-check"></i><b>7</b> Text mining</a><ul>
<li class="chapter" data-level="7.1" data-path="text-mining.html"><a href="text-mining.html#what-were-the-most-common-words-used-in-newspaper-titles-in-the-nineteenth-century_"><i class="fa fa-check"></i><b>7.1</b> What were the most common words used in newspaper titles in the nineteenth century?_</a><ul>
<li class="chapter" data-level="7.1.1" data-path="text-mining.html"><a href="text-mining.html#titles-dont-just-help-you-identity-a-newspaper-but-they-might-tell-you-a-little-bit-about-the-time-in-which-they-were-established.-with-a-bibliographic-list-of-all-our-uk-and-irish-titles-we-can-count-the-most-frequent-words-and-track-them-over-time-and-place-using-text-mining-and-data-analysis."><i class="fa fa-check"></i><b>7.1.1</b> Titles don’t just help you identity a newspaper, but they might tell you a little bit about the time in which they were established. With a bibliographic list of <em>all</em> our UK and Irish titles, we can count the most frequent words and track them over time and place, using text mining and data analysis.</a></li>
<li class="chapter" data-level="7.1.2" data-path="text-mining.html"><a href="text-mining.html#what-is-this-document"><i class="fa fa-check"></i><b>7.1.2</b> What is this document?</a></li>
<li class="chapter" data-level="7.1.3" data-path="text-mining.html"><a href="text-mining.html#how-about-differences-by-country"><i class="fa fa-check"></i><b>7.1.3</b> How about differences by country?</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="extract-text.html"><a href="extract-text.html"><i class="fa fa-check"></i><b>8</b> Make a Text Corpus</a><ul>
<li class="chapter" data-level="8.1" data-path="extract-text.html"><a href="extract-text.html#where-is-this-data"><i class="fa fa-check"></i><b>8.1</b> Where is this data?</a></li>
<li class="chapter" data-level="8.2" data-path="extract-text.html"><a href="extract-text.html#folder-structure"><i class="fa fa-check"></i><b>8.2</b> Folder structure</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="term-frequencies.html"><a href="term-frequencies.html"><i class="fa fa-check"></i><b>9</b> Term Frequencies</a></li>
<li class="chapter" data-level="10" data-path="tf-idf.html"><a href="tf-idf.html"><i class="fa fa-check"></i><b>10</b> Tf_idf:</a></li>
<li class="chapter" data-level="11" data-path="sentiment-analysis.html"><a href="sentiment-analysis.html"><i class="fa fa-check"></i><b>11</b> Sentiment analysis</a><ul>
<li class="chapter" data-level="11.1" data-path="sentiment-analysis.html"><a href="sentiment-analysis.html#install-and-load-relevant-packages"><i class="fa fa-check"></i><b>11.1</b> Install and load relevant packages</a></li>
<li class="chapter" data-level="11.2" data-path="sentiment-analysis.html"><a href="sentiment-analysis.html#fetch-sentiment-data"><i class="fa fa-check"></i><b>11.2</b> Fetch sentiment data</a><ul>
<li class="chapter" data-level="11.2.1" data-path="sentiment-analysis.html"><a href="sentiment-analysis.html#afinn-dataset"><i class="fa fa-check"></i><b>11.2.1</b> Afinn dataset</a></li>
<li class="chapter" data-level="11.2.2" data-path="sentiment-analysis.html"><a href="sentiment-analysis.html#bing-dataset"><i class="fa fa-check"></i><b>11.2.2</b> Bing dataset</a></li>
<li class="chapter" data-level="11.2.3" data-path="sentiment-analysis.html"><a href="sentiment-analysis.html#loughran-dataset"><i class="fa fa-check"></i><b>11.2.3</b> Loughran dataset</a></li>
<li class="chapter" data-level="11.2.4" data-path="sentiment-analysis.html"><a href="sentiment-analysis.html#nrc-dataset"><i class="fa fa-check"></i><b>11.2.4</b> NRC dataset</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="sentiment-analysis.html"><a href="sentiment-analysis.html#load-the-tokenised-news-sample"><i class="fa fa-check"></i><b>11.3</b> Load the tokenised news sample</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="topic-modelling.html"><a href="topic-modelling.html"><i class="fa fa-check"></i><b>12</b> Topic modelling</a></li>
<li class="chapter" data-level="13" data-path="detecting-text-reuse-in-newspaper-articles-.html"><a href="detecting-text-reuse-in-newspaper-articles-.html"><i class="fa fa-check"></i><b>13</b> Detecting text reuse in newspaper articles.</a><ul>
<li class="chapter" data-level="13.1" data-path="detecting-text-reuse-in-newspaper-articles-.html"><a href="detecting-text-reuse-in-newspaper-articles-.html#turn-the-newspaper-sample-into-a-bunch-of-text-documents-one-per-article"><i class="fa fa-check"></i><b>13.1</b> Turn the newspaper sample into a bunch of text documents, one per article</a><ul>
<li class="chapter" data-level="13.1.1" data-path="detecting-text-reuse-in-newspaper-articles-.html"><a href="detecting-text-reuse-in-newspaper-articles-.html#load-the-dataframe-and-preprocess"><i class="fa fa-check"></i><b>13.1.1</b> Load the dataframe and preprocess</a></li>
<li class="chapter" data-level="13.1.2" data-path="detecting-text-reuse-in-newspaper-articles-.html"><a href="detecting-text-reuse-in-newspaper-articles-.html#make-a-text-file-from-each-article"><i class="fa fa-check"></i><b>13.1.2</b> Make a text file from each article</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="detecting-text-reuse-in-newspaper-articles-.html"><a href="detecting-text-reuse-in-newspaper-articles-.html#load-the-files-as-a-textreusecorpus"><i class="fa fa-check"></i><b>13.2</b> Load the files as a TextReuseCorpus</a><ul>
<li class="chapter" data-level="13.2.1" data-path="detecting-text-reuse-in-newspaper-articles-.html"><a href="detecting-text-reuse-in-newspaper-articles-.html#generate-a-minhash"><i class="fa fa-check"></i><b>13.2.1</b> Generate a minhash</a></li>
<li class="chapter" data-level="13.2.2" data-path="detecting-text-reuse-in-newspaper-articles-.html"><a href="detecting-text-reuse-in-newspaper-articles-.html#create-the-textreusecorpus"><i class="fa fa-check"></i><b>13.2.2</b> Create the TextReuseCorpus</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="detecting-text-reuse-in-newspaper-articles-.html"><a href="detecting-text-reuse-in-newspaper-articles-.html#further-reading"><i class="fa fa-check"></i><b>13.3</b> Further reading</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="further-reading-1.html"><a href="further-reading-1.html"><i class="fa fa-check"></i><b>14</b> Further reading</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Demystifying Newspaper Data with R (and a tiny bit of Python)</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="term-frequencies" class="section level1">
<h1><span class="header-section-number">9</span> Term Frequencies</h1>
<p>Use the dataframe to get lists of top words, separated by date/issue etc.</p>
<div class="sourceCode" id="cb197"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb197-1" data-line-number="1"><span class="kw">load</span>(<span class="st">&#39;news_sample_dataframe&#39;</span>)</a></code></pre></div>
<div class="sourceCode" id="cb198"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb198-1" data-line-number="1"><span class="kw">library</span>(tidyverse)</a>
<a class="sourceLine" id="cb198-2" data-line-number="2"><span class="kw">library</span>(tidytext)</a></code></pre></div>
<p>The data frame has a row per article. This is a really easy format to do text mining with, using the techniques from here: <a href="https://www.tidytextmining.com/" class="uri">https://www.tidytextmining.com/</a></p>
<div class="sourceCode" id="cb199"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb199-1" data-line-number="1"><span class="kw">glimpse</span>(news_sample_dataframe)</a></code></pre></div>
<pre><code>## Observations: 621
## Variables: 7
## $ article_code &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1…
## $ art          &lt;chr&gt; &quot;0001&quot;, &quot;0002&quot;, &quot;0003&quot;, &quot;0005&quot;, &quot;0007&quot;, &quot;0008&quot;, &quot;0009&quot;, …
## $ text         &lt;chr&gt; &quot;:THE  NATIONAL  REGIS  ..  _.  •f.4r)i  ,&amp;#34;•)&#39;;  1 S…
## $ title        &lt;chr&gt; &quot;0002644&quot;, &quot;0002644&quot;, &quot;0002644&quot;, &quot;0002644&quot;, &quot;0002644&quot;, &quot;…
## $ year         &lt;chr&gt; &quot;1809&quot;, &quot;1809&quot;, &quot;1809&quot;, &quot;1809&quot;, &quot;1809&quot;, &quot;1809&quot;, &quot;1809&quot;, …
## $ date         &lt;chr&gt; &quot;0101&quot;, &quot;0101&quot;, &quot;0101&quot;, &quot;0101&quot;, &quot;0101&quot;, &quot;0101&quot;, &quot;0101&quot;, …
## $ full_date    &lt;date&gt; 1809-01-01, 1809-01-01, 1809-01-01, 1809-01-01, 1809-01…</code></pre>
<p>Most analysis involves tokenising the text. This divides the text into ‘tokens’ - representing one unit. A unit is often a word, but could be a bigram - a sequence of two consecutive words, or a trigram, a sequence of three consecutive words. With the library <code>tidytext</code>, this is done using a function called <code>unnest_tokens()</code>. This will split the column containing the text of the article into a long dataframe, with one word per row.</p>
<p>The two most important arguments to ``unnest_tokens<code>are</code>output<code>and</code>input```. This is fairly self explanatory. Just pass it the name you would like to give the new column of words (or n-grams) and the column you’d like to split up: in this case the original column is called ‘text’, and we’d like our column of words to be called words.</p>
<div class="sourceCode" id="cb201"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb201-1" data-line-number="1">news_sample_dataframe <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">unnest_tokens</span>(<span class="dt">output =</span> word, <span class="dt">input =</span> text)</a></code></pre></div>
<pre><code>## # A tibble: 467,021 x 7
##    article_code art   title   year  date  full_date  word       
##           &lt;int&gt; &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt; &lt;date&gt;     &lt;chr&gt;      
##  1            1 0001  0002644 1809  0101  1809-01-01 the        
##  2            1 0001  0002644 1809  0101  1809-01-01 national   
##  3            1 0001  0002644 1809  0101  1809-01-01 regis      
##  4            1 0001  0002644 1809  0101  1809-01-01 f          
##  5            1 0001  0002644 1809  0101  1809-01-01 4r         
##  6            1 0001  0002644 1809  0101  1809-01-01 i          
##  7            1 0001  0002644 1809  0101  1809-01-01 34         
##  8            1 0001  0002644 1809  0101  1809-01-01 1          
##  9            1 0001  0002644 1809  0101  1809-01-01 style      
## 10            1 0001  0002644 1809  0101  1809-01-01 superscript
## # … with 467,011 more rows</code></pre>
<p>I can also specify an argument for token, allowing me to split the text into sentences, characters, lines, or n-grams.If I split into n-grams, I used the argument <code>n</code> to specify how many consecutive words I’d like to use.</p>
<p>Like this:</p>
<div class="sourceCode" id="cb203"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb203-1" data-line-number="1">news_sample_dataframe <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">unnest_tokens</span>(<span class="dt">output =</span> word, <span class="dt">input =</span> text, <span class="dt">token =</span> <span class="st">&#39;ngrams&#39;</span>, <span class="dt">n =</span><span class="dv">3</span>)</a></code></pre></div>
<pre><code>## # A tibble: 465,872 x 7
##    article_code art   title   year  date  full_date  word               
##           &lt;int&gt; &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt; &lt;date&gt;     &lt;chr&gt;              
##  1            1 0001  0002644 1809  0101  1809-01-01 the national regis 
##  2            1 0001  0002644 1809  0101  1809-01-01 national regis f   
##  3            1 0001  0002644 1809  0101  1809-01-01 regis f 4r         
##  4            1 0001  0002644 1809  0101  1809-01-01 f 4r i             
##  5            1 0001  0002644 1809  0101  1809-01-01 4r i 34            
##  6            1 0001  0002644 1809  0101  1809-01-01 i 34 1             
##  7            1 0001  0002644 1809  0101  1809-01-01 34 1 style         
##  8            1 0001  0002644 1809  0101  1809-01-01 1 style superscript
##  9            1 0001  0002644 1809  0101  1809-01-01 style superscript l
## 10            1 0001  0002644 1809  0101  1809-01-01 superscript l style
## # … with 465,862 more rows</code></pre>
<p>Before we do any counting, there’s a couple more processing steps. I’m going to remove ‘stop words’. Stop words are very frequently-used words which often crowd out more interesting results. This isn’t always the case, and you shoudln’t just automatically get rid of them, but rather think about what it is yo uare looking for. For this tutorial, though, the results will be more interesting if it’s not just a bunch of ‘the’ and ‘at’ and so forth.</p>
<p>This is really easy. We load a dataframe of stopwords, which is included in the tidytext package.</p>
<div class="sourceCode" id="cb205"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb205-1" data-line-number="1"><span class="kw">data</span>(<span class="st">&quot;stop_words&quot;</span>)</a></code></pre></div>
<p>Next use the function <code>anti_join()</code>. This bascially removes any word in our word list which is also in the stop words list</p>
<div class="sourceCode" id="cb206"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb206-1" data-line-number="1">news_sample_dataframe <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">unnest_tokens</span>(<span class="dt">output =</span> word, <span class="dt">input =</span> text) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">anti_join</span>(stop_words)</a></code></pre></div>
<pre><code>## Joining, by = &quot;word&quot;</code></pre>
<pre><code>## # A tibble: 222,078 x 7
##    article_code art   title   year  date  full_date  word       
##           &lt;int&gt; &lt;chr&gt; &lt;chr&gt;   &lt;chr&gt; &lt;chr&gt; &lt;date&gt;     &lt;chr&gt;      
##  1            1 0001  0002644 1809  0101  1809-01-01 national   
##  2            1 0001  0002644 1809  0101  1809-01-01 regis      
##  3            1 0001  0002644 1809  0101  1809-01-01 4r         
##  4            1 0001  0002644 1809  0101  1809-01-01 34         
##  5            1 0001  0002644 1809  0101  1809-01-01 1          
##  6            1 0001  0002644 1809  0101  1809-01-01 style      
##  7            1 0001  0002644 1809  0101  1809-01-01 superscript
##  8            1 0001  0002644 1809  0101  1809-01-01 style      
##  9            1 0001  0002644 1809  0101  1809-01-01 superscript
## 10            1 0001  0002644 1809  0101  1809-01-01 l2o        
## # … with 222,068 more rows</code></pre>
<p>A couple of words from the .xml have managed to sneak through our text processing: ‘style’ and ‘superscript’. I’m also going to remove these, plus a few more common OCR errors for the word ‘the’.</p>
<p>I’m also going to remove any word with two or less characters, and any numbers. Again, these are optional steps.</p>
<p>I’ll store the dataframe as a variable called ‘tokenised_news_sample’. I’ll also save it using <code>save()</code>, which turns it into an .rdata file, which can be used later.</p>
<div class="sourceCode" id="cb209"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb209-1" data-line-number="1">tokenised_news_sample =<span class="st"> </span>news_sample_dataframe <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb209-2" data-line-number="2"><span class="st">  </span><span class="kw">unnest_tokens</span>(<span class="dt">output =</span> word, <span class="dt">input =</span> text) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb209-3" data-line-number="3"><span class="st">  </span><span class="kw">anti_join</span>(stop_words) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb209-4" data-line-number="4"><span class="st">  </span><span class="kw">filter</span>(<span class="op">!</span>word <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="st">&#39;superscript&#39;</span>, <span class="st">&#39;style&#39;</span>, <span class="st">&#39;de&#39;</span>, <span class="st">&#39;thle&#39;</span>, <span class="st">&#39;tile&#39;</span>, <span class="st">&#39;tie&#39;</span>, <span class="st">&#39;tire&#39;</span>, <span class="st">&#39;tiie&#39;</span>, <span class="st">&#39;tue&#39;</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb209-5" data-line-number="5"><span class="st">  </span><span class="kw">filter</span>(<span class="op">!</span><span class="kw">str_detect</span>(word, <span class="st">&#39;[0-9]{1,}&#39;</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb209-6" data-line-number="6"><span class="st">  </span><span class="kw">filter</span>(<span class="kw">nchar</span>(word) <span class="op">&gt;</span><span class="st"> </span><span class="dv">2</span>)</a></code></pre></div>
<pre><code>## Joining, by = &quot;word&quot;</code></pre>
<div class="sourceCode" id="cb211"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb211-1" data-line-number="1"><span class="kw">save</span>(tokenised_news_sample, <span class="dt">file =</span> <span class="st">&#39;tokenised_news_sample&#39;</span>)</a></code></pre></div>
<p>Now I can use all the tidyverse commands like filter, count, tally and so forth on the data, making it really easy to do basic analysis like word frequency counting. A couple of examples:</p>
<p>The top words overall:</p>
<div class="sourceCode" id="cb212"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb212-1" data-line-number="1">tokenised_news_sample <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb212-2" data-line-number="2"><span class="st">  </span><span class="kw">group_by</span>(word) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb212-3" data-line-number="3"><span class="st">  </span><span class="kw">tally</span>() <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb212-4" data-line-number="4"><span class="st">  </span><span class="kw">arrange</span>(<span class="kw">desc</span>(n))</a></code></pre></div>
<pre><code>## # A tibble: 45,335 x 2
##    word        n
##    &lt;chr&gt;   &lt;int&gt;
##  1 house     666
##  2 country   621
##  3 duke      577
##  4 street    533
##  5 march     515
##  6 time      504
##  7 clarke    497
##  8 sir       495
##  9 april     484
## 10 army      470
## # … with 45,325 more rows</code></pre>
<p>The top five words for each day in the dataset:</p>
<div class="sourceCode" id="cb214"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb214-1" data-line-number="1">tokenised_news_sample <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb214-2" data-line-number="2"><span class="st">  </span><span class="kw">group_by</span>(full_date, word) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb214-3" data-line-number="3"><span class="st">  </span><span class="kw">tally</span>() <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb214-4" data-line-number="4"><span class="st">  </span><span class="kw">arrange</span>(full_date, <span class="kw">desc</span>(n)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb214-5" data-line-number="5"><span class="st">  </span><span class="kw">group_by</span>(full_date) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb214-6" data-line-number="6"><span class="st">  </span><span class="kw">top_n</span>(<span class="dv">5</span>)</a></code></pre></div>
<pre><code>## Selecting by n</code></pre>
<pre><code>## # A tibble: 90 x 3
## # Groups:   full_date [17]
##    full_date  word          n
##    &lt;date&gt;     &lt;chr&gt;     &lt;int&gt;
##  1 1809-01-01 jan          44
##  2 1809-01-01 street       35
##  3 1809-01-01 country      32
##  4 1809-01-01 guildhall    27
##  5 1809-01-01 madrid       27
##  6 1809-01-08 army         43
##  7 1809-01-08 enemy        36
##  8 1809-01-08 time         31
##  9 1809-01-08 lord         30
## 10 1809-01-08 french       29
## # … with 80 more rows</code></pre>
<p>If we had more than one title, we could look at the top words per title like this:</p>
<div class="sourceCode" id="cb217"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb217-1" data-line-number="1">tokenised_news_sample <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb217-2" data-line-number="2"><span class="st">  </span><span class="kw">group_by</span>(title, full_date, word) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb217-3" data-line-number="3"><span class="st">  </span><span class="kw">tally</span>() <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb217-4" data-line-number="4"><span class="st">  </span><span class="kw">arrange</span>(full_date, <span class="kw">desc</span>(n)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb217-5" data-line-number="5"><span class="st">  </span><span class="kw">group_by</span>(full_date) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb217-6" data-line-number="6"><span class="st">  </span><span class="kw">top_n</span>(<span class="dv">5</span>)</a></code></pre></div>
<pre><code>## Selecting by n</code></pre>
<pre><code>## # A tibble: 90 x 4
## # Groups:   full_date [17]
##    title   full_date  word          n
##    &lt;chr&gt;   &lt;date&gt;     &lt;chr&gt;     &lt;int&gt;
##  1 0002644 1809-01-01 jan          44
##  2 0002644 1809-01-01 street       35
##  3 0002644 1809-01-01 country      32
##  4 0002644 1809-01-01 guildhall    27
##  5 0002644 1809-01-01 madrid       27
##  6 0002644 1809-01-08 army         43
##  7 0002644 1809-01-08 enemy        36
##  8 0002644 1809-01-08 time         31
##  9 0002644 1809-01-08 lord         30
## 10 0002644 1809-01-08 french       29
## # … with 80 more rows</code></pre>
<p>We could also summarise by month, using <code>cut()</code>. This rounds the date down to the nearest day, year or month. Once it’s been rounded down, we can count by this new value.</p>
<div class="sourceCode" id="cb220"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb220-1" data-line-number="1">tokenised_news_sample <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb220-2" data-line-number="2"><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">month =</span> <span class="kw">cut</span>(full_date, <span class="st">&#39;month&#39;</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb220-3" data-line-number="3"><span class="st">  </span><span class="kw">group_by</span>(month, word) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb220-4" data-line-number="4"><span class="st">  </span><span class="kw">tally</span>() <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb220-5" data-line-number="5"><span class="st">  </span><span class="kw">arrange</span>(month, <span class="kw">desc</span>(n)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb220-6" data-line-number="6"><span class="st">  </span><span class="kw">group_by</span>(month) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb220-7" data-line-number="7"><span class="st">  </span><span class="kw">top_n</span>(<span class="dv">5</span>)</a></code></pre></div>
<pre><code>## Selecting by n</code></pre>
<pre><code>## # A tibble: 20 x 3
## # Groups:   month [4]
##    month      word          n
##    &lt;fct&gt;      &lt;chr&gt;     &lt;int&gt;
##  1 1809-01-01 army        199
##  2 1809-01-01 jan         168
##  3 1809-01-01 country     166
##  4 1809-01-01 enemy       163
##  5 1809-01-01 feb         153
##  6 1809-02-01 clarke      300
##  7 1809-02-01 duke        271
##  8 1809-02-01 york        194
##  9 1809-02-01 house       182
## 10 1809-02-01 march       171
## 11 1809-03-01 house       238
## 12 1809-03-01 duke        220
## 13 1809-03-01 march       216
## 14 1809-03-01 april       204
## 15 1809-03-01 clarke      188
## 16 1809-04-01 april       200
## 17 1809-04-01 country     157
## 18 1809-04-01 lord        131
## 19 1809-04-01 house       130
## 20 1809-04-01 guildhall   120</code></pre>
<p>We can also pipe everything directly to a plot. Enemy is a common word: I wonder how many times it was used in each day? Here we use <code>filter()</code> to filter out everything except the word (or words) we’re interested in.</p>
<div class="sourceCode" id="cb223"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb223-1" data-line-number="1">tokenised_news_sample <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb223-2" data-line-number="2"><span class="st">  </span><span class="kw">filter</span>(word <span class="op">==</span><span class="st"> &#39;enemy&#39;</span>) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb223-3" data-line-number="3"><span class="st">  </span><span class="kw">group_by</span>(full_date, word) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb223-4" data-line-number="4"><span class="st">  </span><span class="kw">tally</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">ggplot</span>() <span class="op">+</span><span class="st"> </span><span class="kw">geom_col</span>(<span class="kw">aes</span>(<span class="dt">x =</span> full_date, <span class="dt">y =</span> n))</a></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-173-1.png" width="672" /></p>
<p>Charting a couple of words might be more interesting:</p>
<div class="sourceCode" id="cb224"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb224-1" data-line-number="1">tokenised_news_sample <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb224-2" data-line-number="2"><span class="st">  </span><span class="kw">filter</span>(word <span class="op">%in%</span><span class="st"> </span><span class="kw">c</span>(<span class="st">&#39;enemy&#39;</span>, <span class="st">&#39;france&#39;</span>, <span class="st">&#39;spain&#39;</span>)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb224-3" data-line-number="3"><span class="st">  </span><span class="kw">group_by</span>(full_date, word) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb224-4" data-line-number="4"><span class="st">  </span><span class="kw">tally</span>() <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">ggplot</span>() <span class="op">+</span><span class="st"> </span></a>
<a class="sourceLine" id="cb224-5" data-line-number="5"><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">x =</span> full_date, <span class="dt">y =</span> n, <span class="dt">color =</span> word))</a></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-174-1.png" width="672" /></p>
<div class="sourceCode" id="cb225"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb225-1" data-line-number="1">issue_words =<span class="st"> </span>tokenised_news_sample <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb225-2" data-line-number="2"><span class="st">  </span><span class="kw">count</span>(full_date, word, <span class="dt">sort =</span> <span class="ot">TRUE</span>)</a>
<a class="sourceLine" id="cb225-3" data-line-number="3"></a>
<a class="sourceLine" id="cb225-4" data-line-number="4">total_words &lt;-<span class="st"> </span>issue_words <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb225-5" data-line-number="5"><span class="st">  </span><span class="kw">group_by</span>(full_date) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb225-6" data-line-number="6"><span class="st">  </span><span class="kw">summarize</span>(<span class="dt">total =</span> <span class="kw">sum</span>(n))</a>
<a class="sourceLine" id="cb225-7" data-line-number="7"></a>
<a class="sourceLine" id="cb225-8" data-line-number="8">issue_words &lt;-<span class="st"> </span><span class="kw">left_join</span>(issue_words, total_words)</a></code></pre></div>
<pre><code>## Joining, by = &quot;full_date&quot;</code></pre>
<div class="sourceCode" id="cb227"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb227-1" data-line-number="1">issue_words</a></code></pre></div>
<pre><code>## # A tibble: 97,885 x 4
##    full_date  word         n total
##    &lt;date&gt;     &lt;chr&gt;    &lt;int&gt; &lt;int&gt;
##  1 1809-03-19 duke       129 14883
##  2 1809-01-22 majesty    107 10493
##  3 1809-02-12 clarke     103 10924
##  4 1809-03-12 clarke     100 13465
##  5 1809-03-19 evidence   100 14883
##  6 1809-03-19 house       98 14883
##  7 1809-02-19 duke        92 10440
##  8 1809-02-19 clarke      88 10440
##  9 1809-02-05 clarke      83 11337
## 10 1809-03-19 clarke      80 14883
## # … with 97,875 more rows</code></pre>
<div class="sourceCode" id="cb229"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb229-1" data-line-number="1">issue_words <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">ggplot</span>() <span class="op">+</span><span class="st"> </span><span class="kw">geom_histogram</span>(<span class="kw">aes</span>(<span class="dt">x =</span> n<span class="op">/</span>total, <span class="dt">fill =</span>  <span class="kw">as.factor</span>(full_date))) <span class="op">+</span><span class="st"> </span><span class="kw">facet_wrap</span>(<span class="op">~</span>full_date, <span class="dt">scales =</span> <span class="st">&#39;free&#39;</span>)</a></code></pre></div>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="_main_files/figure-html/unnamed-chunk-176-1.png" width="672" /></p>

</div>
            </section>

          </div>
        </div>
      </div>
<a href="extract-text.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="tf-idf.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

</body>

</html>
